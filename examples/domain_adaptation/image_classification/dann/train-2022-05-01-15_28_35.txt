Namespace(arch='resnet50', batch_size=16, bottleneck_dim=256, data='ImageNet50', epochs=300, iters_per_epoch=1000, log='dann', lr=0.01, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', print_freq=100, resize_size=224, root='/data/ImageNet_dataset/v100/jin/', scratch=False, seed=None, source=['IN'], target=['gray'], trade_off=1.0, train_resizing='custom.target', val_resizing='custom.target', weight_decay=0.001, workers=2)
train_transform:  Compose(
    Compose(
    ResizeImage(size=(224, 224))
    CenterCrop(size=(224, 224))
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
)
val_transform:  Compose(
    Compose(
    ResizeImage(size=(224, 224))
    CenterCrop(size=(224, 224))
)
    ToTensor()
)
=> using model 'resnet50'
lr: 0.001
tensor([[0.1608, 0.1176, 0.1569,  ..., 0.1020, 0.1020, 0.1020],
        [0.1098, 0.1176, 0.1490,  ..., 0.1059, 0.1020, 0.1020],
        [0.0627, 0.1176, 0.1451,  ..., 0.1059, 0.1059, 0.1020],
        ...,
        [0.2392, 0.2667, 0.2863,  ..., 0.2039, 0.1216, 0.1647],
        [0.2392, 0.2667, 0.2863,  ..., 0.1882, 0.1255, 0.1569],
        [0.2471, 0.2745, 0.2941,  ..., 0.1765, 0.1255, 0.1490]])
tensor([[0.1608, 0.1176, 0.1569,  ..., 0.1020, 0.1020, 0.1020],
        [0.1098, 0.1176, 0.1490,  ..., 0.1059, 0.1020, 0.1020],
        [0.0627, 0.1176, 0.1451,  ..., 0.1059, 0.1059, 0.1020],
        ...,
        [0.2392, 0.2667, 0.2863,  ..., 0.2039, 0.1216, 0.1647],
        [0.2392, 0.2667, 0.2863,  ..., 0.1882, 0.1255, 0.1569],
        [0.2471, 0.2745, 0.2941,  ..., 0.1765, 0.1255, 0.1490]])
tensor([[0.1608, 0.1176, 0.1569,  ..., 0.1020, 0.1020, 0.1020],
        [0.1098, 0.1176, 0.1490,  ..., 0.1059, 0.1020, 0.1020],
        [0.0627, 0.1176, 0.1451,  ..., 0.1059, 0.1059, 0.1020],
        ...,
        [0.2392, 0.2667, 0.2863,  ..., 0.2039, 0.1216, 0.1647],
        [0.2392, 0.2667, 0.2863,  ..., 0.1882, 0.1255, 0.1569],
        [0.2471, 0.2745, 0.2941,  ..., 0.1765, 0.1255, 0.1490]])
Traceback (most recent call last):
  File "dann.py", line 294, in <module>
    main(args)
  File "dann.py", line 145, in main
    lr_scheduler, epoch, args)
  File "dann.py", line 218, in train
    loss.backward()
  File "/opt/conda/lib/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
