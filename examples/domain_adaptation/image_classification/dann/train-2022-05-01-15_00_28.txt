Namespace(arch='resnet50', batch_size=16, bottleneck_dim=256, data='ImageNet50', epochs=300, iters_per_epoch=1000, log='dann', lr=0.01, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', print_freq=100, resize_size=224, root='/data/ImageNet_dataset/v100/jin/', scratch=False, seed=None, source=['IN'], target=['gray'], trade_off=1.0, train_resizing='custom.target', val_resizing='custom.target', weight_decay=0.001, workers=2)
train_transform:  Compose(
    Compose(
    ResizeImage(size=(224, 224))
    CenterCrop(size=(224, 224))
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
val_transform:  Compose(
    Compose(
    ResizeImage(size=(224, 224))
    CenterCrop(size=(224, 224))
)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
=> using model 'resnet50'
lr: 0.001
<class 'torch.Tensor'>
Epoch: [0][   0/1000]	Time  1.96 ( 1.96)	Data  0.01 ( 0.01)	Loss   4.62 (  4.62)	Cls Acc 0.0 (0.0)	Domain Acc 53.1 (53.1)
<class 'torch.Tensor'>
<class 'torch.Tensor'>
<class 'torch.Tensor'>
<class 'torch.Tensor'>
<class 'torch.Tensor'>
<class 'torch.Tensor'>
<class 'torch.Tensor'>
<class 'torch.Tensor'>
<class 'torch.Tensor'>
<class 'torch.Tensor'>
<class 'torch.Tensor'>
<class 'torch.Tensor'>
Traceback (most recent call last):
  File "dann.py", line 292, in <module>
    main(args)
  File "dann.py", line 145, in main
    lr_scheduler, epoch, args)
  File "dann.py", line 216, in train
    loss.backward()
  File "/opt/conda/lib/python3.6/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt
