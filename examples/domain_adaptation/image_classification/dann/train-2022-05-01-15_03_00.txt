Namespace(arch='resnet50', batch_size=16, bottleneck_dim=256, data='ImageNet50', epochs=300, iters_per_epoch=1000, log='dann', lr=0.01, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', print_freq=100, resize_size=224, root='/data/ImageNet_dataset/v100/jin/', scratch=False, seed=None, source=['IN'], target=['gray'], trade_off=1.0, train_resizing='custom.target', val_resizing='custom.target', weight_decay=0.001, workers=2)
train_transform:  Compose(
    Compose(
    ResizeImage(size=(224, 224))
    CenterCrop(size=(224, 224))
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
val_transform:  Compose(
    Compose(
    ResizeImage(size=(224, 224))
    CenterCrop(size=(224, 224))
)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
=> using model 'resnet50'
lr: 0.001
torch.Size([224, 224])
tensor([[-1.3704, -1.4405, -1.5105,  ..., -1.5980, -1.6155, -1.5630],
        [-1.4930, -1.5630, -1.4405,  ..., -1.5805, -1.5455, -1.5805],
        [-1.3704, -1.4055, -1.3179,  ..., -1.5980, -1.5630, -1.5280],
        ...,
        [-1.0553, -1.4930, -1.3704,  ..., -0.7752,  1.2556,  0.5553],
        [-1.0553, -1.2129, -0.7577,  ...,  1.9909,  0.8880,  0.0651],
        [-0.5651,  0.0301,  0.4853,  ...,  0.6604, -0.1099,  0.2052]])
Epoch: [0][   0/1000]	Time  1.38 ( 1.38)	Data  0.01 ( 0.01)	Loss   4.87 (  4.87)	Cls Acc 6.2 (6.2)	Domain Acc 56.2 (56.2)
torch.Size([224, 224])
tensor([[-0.0574, -0.1625, -0.1975,  ..., -1.6155, -1.6331, -1.6506],
        [-0.2325, -0.2850, -0.3025,  ..., -1.6856, -1.7556, -1.8081],
        [-0.5126, -0.5126, -0.5126,  ..., -1.7906, -1.8256, -1.8606],
        ...,
        [-1.8957, -1.9132, -1.9307,  ...,  1.2031,  1.0280,  0.8529],
        [-1.9307, -1.9307, -1.9307,  ...,  1.5357,  1.5007,  1.4132],
        [-1.9307, -1.9307, -1.9307,  ...,  1.7458,  1.7633,  1.7458]])
torch.Size([224, 224])
tensor([[ 0.4678,  0.5553,  0.5728,  ...,  0.1176,  0.1176,  0.1877],
        [ 0.5203,  0.5028,  0.5203,  ...,  0.1702,  0.1527,  0.2227],
        [ 0.5553,  0.5378,  0.6078,  ...,  0.2927,  0.1877,  0.1001],
        ...,
        [-0.7052, -0.5301, -0.3901,  ..., -0.4426, -0.4601, -0.3200],
        [-0.5476, -0.5301, -0.4601,  ..., -0.6352, -0.5301, -0.4426],
        [-0.5651, -0.4251, -0.2850,  ..., -0.6176, -0.5476, -0.4426]])
torch.Size([224, 224])
tensor([[-1.1253, -1.3354, -0.6527,  ..., -0.4951, -0.4951, -0.6527],
        [-0.6702, -1.0728, -0.6702,  ..., -0.6527, -0.5476, -0.5126],
        [-0.3901, -0.6527, -0.7927,  ..., -0.3200, -0.5126, -0.5301],
        ...,
        [-0.0924, -0.0224, -0.1800,  ..., -0.0224,  0.0826, -0.0399],
        [-0.9853, -1.0378, -1.0203,  ...,  0.1527,  0.2227,  0.0126],
        [-0.5651, -0.7227, -0.7752,  ...,  0.1001,  0.1702, -0.0399]])
torch.Size([224, 224])
tensor([[-0.7227, -0.4951, -0.3901,  ..., -1.8957, -1.8957, -1.8957],
        [-0.4251, -0.3901, -0.3375,  ..., -1.9132, -1.9132, -1.9132],
        [-0.3375, -0.3725, -0.3550,  ..., -1.8957, -1.8957, -1.8957],
        ...,
        [ 0.3102,  0.4678,  0.3102,  ..., -0.7052, -0.8452, -0.8627],
        [ 0.0826,  0.0651, -0.0049,  ..., -0.7402, -0.8803, -0.8277],
        [-0.1275, -0.0399,  0.0301,  ..., -0.5826, -0.4776, -0.7402]])
Traceback (most recent call last):
  File "dann.py", line 293, in <module>
    main(args)
  File "dann.py", line 145, in main
    lr_scheduler, epoch, args)
  File "dann.py", line 185, in train
    x_s, labels_s = next(train_source_iter)
  File "/src/Transfer-Learning-Library/common/utils/data.py", line 50, in __next__
    data = next(self.iter)
  File "/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1182, in _next_data
    idx, data = self._get_data()
  File "/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 1148, in _get_data
    success, data = self._try_get_data()
  File "/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 986, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/opt/conda/lib/python3.6/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/opt/conda/lib/python3.6/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/opt/conda/lib/python3.6/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/opt/conda/lib/python3.6/multiprocessing/connection.py", line 911, in wait
    ready = selector.select(timeout)
  File "/opt/conda/lib/python3.6/selectors.py", line 376, in select
    fd_event_list = self._poll.poll(timeout)
KeyboardInterrupt
