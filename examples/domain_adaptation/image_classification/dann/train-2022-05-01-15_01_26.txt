Namespace(arch='resnet50', batch_size=16, bottleneck_dim=256, data='ImageNet50', epochs=300, iters_per_epoch=1000, log='dann', lr=0.01, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', print_freq=100, resize_size=224, root='/data/ImageNet_dataset/v100/jin/', scratch=False, seed=None, source=['IN'], target=['gray'], trade_off=1.0, train_resizing='custom.target', val_resizing='custom.target', weight_decay=0.001, workers=2)
train_transform:  Compose(
    Compose(
    ResizeImage(size=(224, 224))
    CenterCrop(size=(224, 224))
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
val_transform:  Compose(
    Compose(
    ResizeImage(size=(224, 224))
    CenterCrop(size=(224, 224))
)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
=> using model 'resnet50'
lr: 0.001
torch.Size([16, 3, 224, 224])
Epoch: [0][   0/1000]	Time  1.45 ( 1.45)	Data  0.01 ( 0.01)	Loss   4.72 (  4.72)	Cls Acc 0.0 (0.0)	Domain Acc 46.9 (46.9)
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
torch.Size([16, 3, 224, 224])
Traceback (most recent call last):
  File "dann.py", line 292, in <module>
    main(args)
  File "dann.py", line 145, in main
    lr_scheduler, epoch, args)
  File "dann.py", line 204, in train
    transfer_loss = domain_adv(f_s, f_t)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/src/Transfer-Learning-Library/dalib/adaptation/dann.py", line 73, in forward
    d_label_s = torch.ones((f_s.size(0), 1)).to(f_s.device)
KeyboardInterrupt
