Namespace(arch='resnet50', batch_size=8, bottleneck_dim=256, data='ImageNet50', epochs=1000, iters_per_epoch=1000, log='dann', lr=0.01, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', print_freq=100, resize_size=224, root='/media/ImageNet_dataset/v100/jin/', scratch=False, seed=None, source=['IN'], target=['gray'], trade_off=1.0, train_resizing='custom.source', val_resizing='custom.source', weight_decay=0.001, workers=2)
source train_transform:  Compose(
    Compose(
    ResizeImage(size=(448, 448))
    CenterCrop(size=(448, 448))
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
)
target train_transform:  Compose(
    Compose(
    ResizeImage(size=(448, 448))
    CenterCrop(size=(448, 448))
    Grayscale(num_output_channels=1)
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
)
val_transform:  Compose(
    Compose(
    ResizeImage(size=(448, 448))
    CenterCrop(size=(448, 448))
)
    ToTensor()
)
train_target_transform is Not None
=> using model 'resnet50'
lr: 0.001
source shape  torch.Size([8, 3, 448, 448])
torch.Size([8, 1, 448, 448])
Traceback (most recent call last):
  File "dann.py", line 304, in <module>
    main(args)
  File "dann.py", line 148, in main
    train(train_source_iter, train_target_iter, classifier, domain_adv, optimizer,
  File "dann.py", line 213, in train
    y_t, f_t = model(x_t)
  File "/home/jin2/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/jin2/pytorch-image-models/Transfer-Learning-Library/common/modules/classifier.py", line 80, in forward
    f = self.pool_layer(self.backbone(x))
  File "/home/jin2/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/jin2/pytorch-image-models/Transfer-Learning-Library/common/vision/models/resnet.py", line 27, in forward
    x = self.conv1(x)
  File "/home/jin2/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/jin2/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 399, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/jin2/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 395, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[8, 1, 448, 448] to have 3 channels, but got 1 channels instead
