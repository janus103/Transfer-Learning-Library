Namespace(arch='resnet50', batch_size=8, bottleneck_dim=256, data='ImageNet50', epochs=100, iters_per_epoch=1000, log='dann', lr=0.01, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, no_hflip=False, no_pool=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), per_class_eval=False, phase='train', print_freq=100, resize_size=224, root='/data/ImageNet_dataset/v100/jin', scratch=False, seed=None, source=['IN'], target=['gray'], trade_off=1.0, train_resizing='custom.target', val_resizing='custom.target', weight_decay=0.001, workers=2)
train_transform:  Compose(
    Compose(
    ResizeImage(size=(224, 224))
    CenterCrop(size=(224, 224))
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
val_transform:  Compose(
    Compose(
    ResizeImage(size=(224, 224))
    CenterCrop(size=(224, 224))
)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
=> using model 'resnet50'
lr: 0.001
Epoch: [0][   0/1000]	Time  1.14 ( 1.14)	Data  0.01 ( 0.01)	Loss   4.27 (  4.27)	Cls Acc 25.0 (25.0)	Domain Acc 37.5 (37.5)
Traceback (most recent call last):
  File "dann.py", line 290, in <module>
    main(args)
  File "dann.py", line 145, in main
    lr_scheduler, epoch, args)
  File "dann.py", line 188, in train
    x_s = x_s.to(device)
KeyboardInterrupt
